{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9510863,"sourceType":"datasetVersion","datasetId":5789245},{"sourceId":9515759,"sourceType":"datasetVersion","datasetId":5793015}],"dockerImageVersionId":30775,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install openai","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-30T13:13:53.733912Z","iopub.execute_input":"2024-09-30T13:13:53.734905Z","iopub.status.idle":"2024-09-30T13:13:55.787710Z","shell.execute_reply.started":"2024-09-30T13:13:53.734857Z","shell.execute_reply":"2024-09-30T13:13:55.786062Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"^C\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n    return _run_code(code, main_globals, None,\n  File \"/opt/conda/lib/python3.10/runpy.py\", line 86, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/lib/python3.10/site-packages/pip/__main__.py\", line 24, in <module>\n    sys.exit(_main())\n  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/cli/main.py\", line 77, in main\n    command = create_command(cmd_name, isolated=(\"--isolated\" in cmd_args))\n  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/commands/__init__.py\", line 114, in create_command\n    module = importlib.import_module(module_path)\n  File \"/opt/conda/lib/python3.10/importlib/__init__.py\", line 126, in import_module\n    return _bootstrap._gcd_import(name[level:], package, level)\n  File \"<frozen importlib._bootstrap>\", line 1050, in _gcd_import\n  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/commands/install.py\", line 15, in <module>\n    from pip._internal.cli.req_command import (\n  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/cli/req_command.py\", line 20, in <module>\n    from pip._internal.index.collector import LinkCollector\n  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/index/collector.py\", line 36, in <module>\n    from pip._internal.models.search_scope import SearchScope\n  File \"/opt/conda/lib/python3.10/site-packages/pip/_internal/models/search_scope.py\", line 14, in <module>\n    logger = logging.getLogger(__name__)\n  File \"/opt/conda/lib/python3.10/logging/__init__.py\", line 2077, in getLogger\n    if not name or isinstance(name, str) and name == root.name:\nKeyboardInterrupt\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# 先让大模型对图片进行描述，再用提示词输出标签（两步prompt）","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torchvision import datasets, transforms\nimport openai\nimport base64\nimport requests\n\nimport io\nfrom PIL import Image\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\n\n# 设置API密钥\nopenai.api_key = ' '\n# 预定义Fashion MNIST的标签\nfashion_labels = [\n    'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'\n]\n\n\n# 定义图像转换：将图像转换为Tensor，并进行标准化\ntransform = transforms.Compose([\n    transforms.ToTensor(),  # 将图像转换为Tensor\n    transforms.Normalize((0.5,), (0.5,))  # 标准化处理\n])\n\n# 加载Fashion MNIST测试数据\ntest_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n# 创建数据加载器，将数据按批次加载，并禁用随机打乱（shuffle）\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n\n# 限制处理图像的数量\nnum_samples = 20  # 控制处理图片的数量以节约成本，可以根据需要调整\n\n# 获取自定义提示文本的函数\ndef get_prompt():\n    # 输入第一次提示的文本\n    first_prompt = input(\"Please enter the first text prompt: \")\n\n    # 输入第二次提示的文本\n    second_prompt = input(\"Please enter the second text prompt for accuracy computation: \")\n\n    return first_prompt, second_prompt\n\n# 定义图像编码函数\ndef encode_image(image_path):\n    buffered = io.BytesIO()\n    image_path.save(buffered, format=\"JPEG\")\n    return base64.b64encode(buffered.getvalue()).decode('utf-8')\n\n# 定义分类函数\ndef classify_image(image_tensor, prompt_text):\n    # 将图像Tensor转换为PIL图像对象\n    pil_image = transforms.ToPILImage()(image_tensor[0])\n    \n    # 将图像编码为base64\n    base64_image = encode_image(pil_image)\n\n    # 构建请求头和负载\n    headers = {\n        \"Content-Type\": \"application/json\",\n        \"Authorization\": f\"Bearer {openai.api_key}\"\n    }\n\n    payload = {\n        \"model\": \"gpt-4o-2024-08-06\",\n        \"messages\": [\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\n                        \"type\": \"text\",\n                        \"text\": prompt_text  # 使用输入的提示文本\n                    },\n                    {\n                        \"type\": \"image_url\",\n                        \"image_url\": {\n                            \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n                        }\n                    }\n                ]\n            }\n        ],\n        \"max_tokens\": 300\n    }\n\n    try:\n        # 调用OpenAI API\n        response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n        \n        if response.status_code == 200:\n            # 获取模型的回复\n            model_response = response.json()\n            model_content = model_response['choices'][0]['message']['content'].strip()\n            print(f\"Model response: {model_content}\")\n\n            # 逐个标签进行匹配\n            for i, label in enumerate(fashion_labels):\n                if label.lower() in model_content.lower():  # 如果标签在响应中出现\n                    return i  # 返回匹配的标签索引\n        else:\n            print(f\"Request failed with status: {response.status_code}, {response.text}\")\n    \n    except Exception as e:\n        print(f\"Error processing image: {e}\")  # 打印错误信息\n\n    return -1  # 返回错误标识\n\n# 获取用户提示输入\nfirst_prompt, second_prompt = get_prompt()\n\n# 存储预测结果和值得评估的真实标签\ny_pred = []  # 存储预测结果\ny_true = []  # 存储真实标签\n\n# 遍历测试加载器中的样本\nfor idx, (image, label) in enumerate(test_loader):\n    if idx >= num_samples:  # 如果达到样本数量限制，则停止\n        break\n    predicted_label = classify_image(image, first_prompt)  # 对图像进行第一次分类\n    y_pred.append(predicted_label)  # 存储预测标签\n    y_true.append(label.item())  # 存储真实标签\n\n# 重新评估用第二个提示进行的预测\ny_pred_second = []\n\nfor idx, (image, label) in enumerate(test_loader):\n    if idx >= num_samples:\n        break\n    predicted_label = classify_image(image, second_prompt)\n    y_pred_second.append(predicted_label)\n\n# 计算准确率\naccuracy = accuracy_score(y_true, y_pred_second)\nprint(f\"Accuracy with second prompt: {accuracy}\")  # 打印使用第二次提示的准确率\n\n# 可视化一些样本图像和预测结果\nfor i in range(num_samples):\n    # 将Tensor图像转换为二维图像并显示\n    plt.imshow(test_dataset[i][0].permute(1, 2, 0).numpy().squeeze(), cmap='gray')\n    true_label = fashion_labels[y_true[i]]  # 获取真实标签\n    predicted_label = fashion_labels[y_pred_second[i]] if y_pred_second[i] != -1 else \"Unknown\"  # 获取预测标签\n    plt.title(f'True: {true_label}, Pred: {predicted_label}')  # 设置标题为真实和预测标签\n    plt.show()  # 显示图像\n","metadata":{"execution":{"iopub.status.busy":"2024-09-30T13:13:55.791133Z","iopub.execute_input":"2024-09-30T13:13:55.791645Z","iopub.status.idle":"2024-09-30T13:14:01.593148Z","shell.execute_reply.started":"2024-09-30T13:13:55.791587Z","shell.execute_reply":"2024-09-30T13:14:01.590743Z"},"trusted":true},"execution_count":2,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datasets, transforms\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbase64\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openai'"],"ename":"ModuleNotFoundError","evalue":"No module named 'openai'","output_type":"error"}]},{"cell_type":"markdown","source":"# 第一步给一张图片作为prompt，第二步给文本prompt要求分类，以第二步的输出进行准确度计算（两步不同输入的prompt）","metadata":{}},{"cell_type":"code","source":"\nimport torch\nfrom torchvision import datasets, transforms\nimport openai\nimport base64\nimport requests\n\nimport io\nfrom PIL import Image\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\n\n# 设置API密钥\nopenai.api_key = ' '\n\n# 预定义Fashion MNIST标签\nfashion_labels = [\n    'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'\n]\n\n# 定义图像转换，将图像转换为Tensor并标准化\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\n\n# 加载Fashion MNIST测试数据\ntest_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n\n# 创建数据加载器\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n\n# 限制处理图像的数量\nnum_samples = 20\n\n# 函数：将图像编码为base64\ndef encode_image(image):\n    if image.mode == 'RGBA':\n        image = image.convert('RGB')\n    \n    buffered = io.BytesIO()\n    image.save(buffered, format=\"JPEG\")\n    return base64.b64encode(buffered.getvalue()).decode('utf-8')\n\n# 第一步：输入自定义图片作为概念理解的预置\ndef get_image_prompt():\n    image_path = input(\"Enter the path of the image to use as a conceptual prompt: \")\n    try:\n        image = Image.open(image_path)\n        return encode_image(image)\n    except Exception as e:\n        print(f\"Could not open image: {e}\")\n        return None\n\n# 第二步：输入自定义文本prompt\ndef get_text_prompt():\n    return input(\"Please enter your text prompt: \")\n\n# 函数：使用API进行图像分类\ndef classify_image(image_tensor, prompt_text):\n    pil_image = transforms.ToPILImage()(image_tensor[0])\n    base64_image = encode_image(pil_image)\n\n    headers = {\n        \"Content-Type\": \"application/json\",\n        \"Authorization\": f\"Bearer {openai.api_key}\"\n    }\n\n    messages_content = [\n        {\n            \"type\": \"text\",\n            \"text\": prompt_text\n        },\n        {\n            \"type\": \"image_url\",\n            \"image_url\": {\n                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n            }\n        }\n    ]\n\n    payload = {\n        \"model\": \"gpt-4o-2024-08-06\",\n        \"messages\": [\n            {\n                \"role\": \"user\",\n                \"content\": messages_content\n            }\n        ],\n        \"max_tokens\": 300\n    }\n\n    try:\n        response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n        \n        if response.status_code == 200:\n            model_response = response.json()\n            model_content = model_response['choices'][0]['message']['content'].strip()\n            print(f\"Model response: {model_content}\")\n\n            for i, label in enumerate(fashion_labels):\n                if label.lower() in model_content.lower():\n                    return i\n        else:\n            print(f\"Request failed with status: {response.status_code}, {response.text}\")\n\n    except Exception as e:\n        print(f\"Error processing image: {e}\")\n\n    return -1\n\n# 存储预测结果和真实标签\ny_pred = []\ny_true = []\n\n# 获取图像prompt\nbase64_image_prompt = get_image_prompt()\nif not base64_image_prompt:\n    print(\"Image prompt not obtained, exiting program.\")\n    exit()\n\n# 将图像prompt用于概念理解，并展示大模型的回复\nheaders = {\n    \"Content-Type\": \"application/json\",\n    \"Authorization\": f\"Bearer {openai.api_key}\"\n}\n\nconcept_payload = {\n    \"model\": \"gpt-4o-2024-08-06\",\n    \"messages\": [\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\n                    \"type\": \"image_url\",\n                    \"image_url\": {\n                        \"url\": f\"data:image/jpeg;base64,{base64_image_prompt}\"\n                    }\n                },\n                {\n                    \"type\": \"text\",\n                    \"text\": \"Please use this image to understand the concept for further classification tasks.\"\n                }\n            ]\n        }\n    ],\n    \"max_tokens\": 300\n}\n\ntry:\n    concept_response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=concept_payload)\n    if concept_response.status_code == 200:\n        concept_model_response = concept_response.json()\n        concept_model_content = concept_model_response['choices'][0]['message']['content'].strip()\n        print(f\"Conceptual understanding response: {concept_model_content}\")\n    else:\n        print(f\"Concept setup failed with status: {concept_response.status_code}, {concept_response.text}\")\nexcept Exception as e:\n    print(f\"Error setting concept: {e}\")\n\n# 获取用户定义的文本提示词\nprompt_text = get_text_prompt()\n\n# 遍历测试加载器中的样本\nfor idx, (image, label) in enumerate(test_loader):\n    if idx >= num_samples:\n        break\n    predicted_label = classify_image(image, prompt_text)\n    y_pred.append(predicted_label)\n    y_true.append(label.item())\n\n# 计算准确率\naccuracy = accuracy_score(y_true, y_pred)\nprint(f\"Accuracy: {accuracy}\")\n\n# 可视化一些样本图像和预测结果\nfor i in range(num_samples):\n    plt.imshow(test_dataset[i][0].permute(1, 2, 0).numpy().squeeze(), cmap='gray')\n    true_label = fashion_labels[y_true[i]]\n    predicted_label = fashion_labels[y_pred[i]] if y_pred[i] != -1 else \"Unknown\"\n    plt.title(f'True: {true_label}, Pred: {predicted_label}')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-30T13:14:01.594545Z","iopub.status.idle":"2024-09-30T13:14:01.595268Z","shell.execute_reply.started":"2024-09-30T13:14:01.594921Z","shell.execute_reply":"2024-09-30T13:14:01.594971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 对每种label提供描述（只有一步prompt）","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torchvision import datasets, transforms\nimport openai\nimport base64\nimport requests\n\nimport io\nfrom PIL import Image\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\n\n# 设置API密钥\nopenai.api_key = '1'\n# 预定义Fashion MNIST的标签\nfashion_labels = [\n    'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', \n    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'\n]\n\n# 定义图像转换：将图像转换为Tensor，并进行标准化\ntransform = transforms.Compose([\n    transforms.ToTensor(),  # 将图像转换为Tensor\n    transforms.Normalize((0.5,), (0.5,))  # 标准化处理\n])\n\n# 加载Fashion MNIST测试数据\ntest_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n# 创建数据加载器，将数据按批次加载，并禁用随机打乱（shuffle）\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n\n# 限制处理图像的数量\nnum_samples = 20  # 控制处理图片的数量以节约成本，可以根据需要调整\n\n# 获取自定义提示文本的函数\ndef get_prompt():\n    # 这里你可以修改提示文本\n    return \"can you help me classify this picture from 'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot', please first tell what shape is inside this picture, then tell what features are these shapes, then generate a label\"\n\n# 定义图像编码函数\ndef encode_image(image_path):\n    buffered = io.BytesIO()\n    image_path.save(buffered, format=\"JPEG\")\n    return base64.b64encode(buffered.getvalue()).decode('utf-8')\n\n# 定义分类函数\ndef classify_image(image_tensor):\n    # 将图像Tensor转换为PIL图像对象\n    pil_image = transforms.ToPILImage()(image_tensor[0])\n    \n    # 将图像编码为base64\n    base64_image = encode_image(pil_image)\n\n    # 构建请求头和负载\n    headers = {\n        \"Content-Type\": \"application/json\",\n        \"Authorization\": f\"Bearer {openai.api_key}\"\n    }\n\n    payload = {\n        \"model\": \"gpt-4o-2024-08-06\",\n        \"messages\": [\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\n                        \"type\": \"text\",\n                        \"text\": get_prompt()  # 使用自定义提示文本\n                    },\n                    {\n                        \"type\": \"image_url\",\n                        \"image_url\": {\n                            \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n                        }\n                    }\n                ]\n            }\n        ],\n        \"max_tokens\": 300\n    }\n\n    try:\n        # 调用OpenAI API\n        response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n        \n        if response.status_code == 200:\n            # 获取模型的回复\n            model_response = response.json()\n            model_content = model_response['choices'][0]['message']['content'].strip()\n            print(f\"Model response: {model_content}\")\n\n            # 逐个标签进行匹配\n            for i, label in enumerate(fashion_labels):\n                if label.lower() in model_content.lower():  # 如果标签在响应中出现\n                    return i  # 返回匹配的标签索引\n        else:\n            print(f\"Request failed with status: {response.status_code}, {response.text}\")\n    \n    except Exception as e:\n        print(f\"Error processing image: {e}\")  # 打印错误信息\n\n    return -1  # 返回错误标识\n\n# 存储预测结果和值得评估的真实标签\ny_pred = []  # 存储预测结果\ny_true = []  # 存储真实标签\n\n# 遍历测试加载器中的样本\nfor idx, (image, label) in enumerate(test_loader):\n    if idx >= num_samples:  # 如果达到样本数量限制，则停止\n        break\n    predicted_label = classify_image(image)  # 对图像进行分类\n    y_pred.append(predicted_label)  # 存储预测标签\n    y_true.append(label.item())  # 存储真实标签\n\n# 计算准确率\naccuracy = accuracy_score(y_true, y_pred)\nprint(f\"Accuracy: {accuracy}\")  # 打印准确率\n\n# 可视化一些样本图像和预测结果\nfor i in range(num_samples):\n    # 将Tensor图像转换为二维图像并显示\n    plt.imshow(test_dataset[i][0].permute(1, 2, 0).numpy().squeeze(), cmap='gray')\n    true_label = fashion_labels[y_true[i]]  # 获取真实标签\n    predicted_label = fashion_labels[y_pred[i]] if y_pred[i] != -1 else \"Unknown\"  # 获取预测标签\n    plt.title(f'True: {true_label}, Pred: {predicted_label}')  # 设置标题为真实和预测标签\n    plt.show()  # 显示图","metadata":{"execution":{"iopub.status.busy":"2024-09-30T13:14:01.598139Z","iopub.status.idle":"2024-09-30T13:14:01.599132Z","shell.execute_reply.started":"2024-09-30T13:14:01.598769Z","shell.execute_reply":"2024-09-30T13:14:01.598804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torchvision import datasets, transforms\nimport openai\nimport base64\nimport requests\n\nimport io\nfrom PIL import Image\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\n\n# 设置API密钥\nopenai.api_key = ' '\n\n# 预定义Fashion MNIST标签\nfashion_labels = [\n    'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'\n]\n\n# 定义图像转换，将图像转换为Tensor并标准化\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\n\n# 加载Fashion MNIST测试数据\ntest_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n\n# 创建数据加载器\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n\n# 限制处理图像的数量\nnum_samples = 20\n\n# 函数：将图像编码为base64\ndef encode_image(image):\n    if image.mode == 'RGBA':\n        image = image.convert('RGB')\n\n    buffered = io.BytesIO()\n    image.save(buffered, format=\"JPEG\")\n    return base64.b64encode(buffered.getvalue()).decode('utf-8')\n\n# 函数：使用API进行图像分类\ndef classify_image(image_tensor, prompt_text):\n    pil_image = transforms.ToPILImage()(image_tensor[0])\n    base64_image = encode_image(pil_image)\n\n    headers = {\n        \"Content-Type\": \"application/json\",\n        \"Authorization\": f\"Bearer {openai.api_key}\"\n    }\n\n    messages_content = [\n        {\n            \"type\": \"text\",\n            \"text\": prompt_text\n        },\n        {\n            \"type\": \"image_url\",\n            \"image_url\": {\n                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n            }\n        }\n    ]\n\n    payload = {\n        \"model\": \"gpt-4o-2024-08-06\",\n        \"messages\": [\n            {\n                \"role\": \"user\",\n                \"content\": messages_content\n            }\n        ],\n        \"max_tokens\": 300\n    }\n\n    try:\n        response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n        \n        if response.status_code == 200:\n            model_response = response.json()\n            model_content = model_response['choices'][0]['message']['content'].strip()\n            print(f\"Model response: {model_content}\")\n\n            for i, label in enumerate(fashion_labels):\n                if label.lower() in model_content.lower():\n                    return i\n        else:\n            print(f\"Request failed with status: {response.status_code}, {response.text}\")\n\n    except Exception as e:\n        print(f\"Error processing image: {e}\")\n\n    return -1\n\n# 再次分类不正确答案的函数\ndef reclassify_incorrect(y_pred, y_true, images, incorrect_prompt):\n    y_pred_rechecked = y_pred.copy()\n    for idx, predicted in enumerate(y_pred):\n        if predicted != y_true[idx]:\n            print(f\"Re-evaluating index {idx}: Original prediction was incorrect.\")\n            y_pred_rechecked[idx] = classify_image(images[idx], incorrect_prompt)\n    return y_pred_rechecked\n\n# 获取用户输入的重新分类提示\ndef get_reclassification_prompt():\n    return input(\"Enter the reclassification prompt for incorrect answers: \")\n\n# 存储预测结果和真实标签\ny_pred = []\ny_true = []\nimages = []  # 存储图像以便于重新分类\n\n# 获取用户定义的文本提示词（用于初次分类）\nprompt_text = input(\"Please enter your text prompt: \")\n\n# 获取用户输入的重新分类提示\nreclassification_prompt = get_reclassification_prompt()\n\n# 遍历测试加载器中的样本\nfor idx, (image, label) in enumerate(test_loader):\n    if idx >= num_samples:\n        break\n    images.append(image)\n    predicted_label = classify_image(image, prompt_text)\n    y_pred.append(predicted_label)\n    y_true.append(label.item())\n\n# 计算第一轮准确率\naccuracy_round1 = accuracy_score(y_true, y_pred)\nprint(f\"Accuracy Round 1: {accuracy_round1}\")\n\n# 第二轮：使用用户输入的提示对不正确的答案进行重新分类\ny_pred_round2 = reclassify_incorrect(y_pred, y_true, images, reclassification_prompt)\naccuracy_round2 = accuracy_score(y_true, y_pred_round2)\nprint(f\"Accuracy Round 2: {accuracy_round2}\")\n\n# 第三轮：再次使用相同的用户输入提示进行再次重新分类\ny_pred_round3 = reclassify_incorrect(y_pred_round2, y_true, images, reclassification_prompt)\naccuracy_round3 = accuracy_score(y_true, y_pred_round3)\nprint(f\"Accuracy Round 3: {accuracy_round3}\")\n\n# 可视化一些样本图像和最终的预测结果\nfor i in range(num_samples):\n    plt.imshow(test_dataset[i][0].permute(1, 2, 0).numpy().squeeze(), cmap='gray')\n    true_label = fashion_labels[y_true[i]]\n    predicted_label = fashion_labels[y_pred_round3[i]] if y_pred_round3[i] != -1 else \"Unknown\"\n    plt.title(f'True: {true_label}, Pred: {predicted_label}')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-30T13:14:01.601272Z","iopub.status.idle":"2024-09-30T13:14:01.601895Z","shell.execute_reply.started":"2024-09-30T13:14:01.601581Z","shell.execute_reply":"2024-09-30T13:14:01.601611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 直接分类，如果错了，告诉大模型有错误，让他重新进行二轮三轮（两步prompt）","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torchvision import datasets, transforms\nimport openai\nimport base64\nimport requests\n\nimport io\nfrom PIL import Image\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\n\n# 设置API密钥\nopenai.api_key = ' '\n\n# 预定义Fashion MNIST标签\nfashion_labels = [\n    'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'\n]\n\n# 定义图像转换，将图像转换为Tensor并标准化\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\n\n# 加载Fashion MNIST测试数据\ntest_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n\n# 创建数据加载器\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n\n# 限制处理图像的数量\nnum_samples = 20\n\n# 函数：将图像编码为base64\ndef encode_image(image):\n    if image.mode == 'RGBA':\n        image = image.convert('RGB')\n\n    buffered = io.BytesIO()\n    image.save(buffered, format=\"JPEG\")\n    return base64.b64encode(buffered.getvalue()).decode('utf-8')\n\n# 函数：使用API进行图像分类\ndef classify_image(image_tensor, prompt_text):\n    pil_image = transforms.ToPILImage()(image_tensor[0])\n    base64_image = encode_image(pil_image)\n\n    headers = {\n        \"Content-Type\": \"application/json\",\n        \"Authorization\": f\"Bearer {openai.api_key}\"\n    }\n\n    messages_content = [\n        {\n            \"type\": \"text\",\n            \"text\": prompt_text\n        },\n        {\n            \"type\": \"image_url\",\n            \"image_url\": {\n                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n            }\n        }\n    ]\n\n    payload = {\n        \"model\": \"gpt-4o-2024-08-06\",\n        \"messages\": [\n            {\n                \"role\": \"user\",\n                \"content\": messages_content\n            }\n        ],\n        \"max_tokens\": 300\n    }\n\n    try:\n        response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n        \n        if response.status_code == 200:\n            model_response = response.json()\n            model_content = model_response['choices'][0]['message']['content'].strip()\n            print(f\"Model response: {model_content}\")\n\n            for i, label in enumerate(fashion_labels):\n                if label.lower() in model_content.lower():\n                    return i\n        else:\n            print(f\"Request failed with status: {response.status_code}, {response.text}\")\n\n    except Exception as e:\n        print(f\"Error processing image: {e}\")\n\n    return -1\n\n# 再次分类不正确答案的函数\ndef reclassify_incorrect(y_pred, y_true, images, incorrect_prompt):\n    y_pred_rechecked = y_pred.copy()\n    for idx, predicted in enumerate(y_pred):\n        if predicted != y_true[idx]:\n            print(f\"Re-evaluating index {idx}: Original prediction was incorrect.\")\n            y_pred_rechecked[idx] = classify_image(images[idx], incorrect_prompt)\n    return y_pred_rechecked\n\n# 获取用户输入的重新分类提示\ndef get_reclassification_prompt():\n    return input(\"Enter the reclassification prompt for incorrect answers: \")\n\n# 存储预测结果和真实标签\ny_pred = []\ny_true = []\nimages = []  # 存储图像以便于重新分类\n\n# 获取用户定义的文本提示词（用于初次分类）\nprompt_text = input(\"Please enter your text prompt: \")\n\n# 获取用户输入的重新分类提示\nreclassification_prompt = get_reclassification_prompt()\n\n# 遍历测试加载器中的样本\nfor idx, (image, label) in enumerate(test_loader):\n    if idx >= num_samples:\n        break\n    images.append(image)\n    predicted_label = classify_image(image, prompt_text)\n    y_pred.append(predicted_label)\n    y_true.append(label.item())\n\n# 计算第一轮准确率\naccuracy_round1 = accuracy_score(y_true, y_pred)\nprint(f\"Accuracy Round 1: {accuracy_round1}\")\n\n# 第二轮：使用用户输入的提示对不正确的答案进行重新分类\ny_pred_round2 = reclassify_incorrect(y_pred, y_true, images, reclassification_prompt)\naccuracy_round2 = accuracy_score(y_true, y_pred_round2)\nprint(f\"Accuracy Round 2: {accuracy_round2}\")\n\n# 第三轮：再次使用相同的用户输入提示进行再次重新分类\ny_pred_round3 = reclassify_incorrect(y_pred_round2, y_true, images, reclassification_prompt)\naccuracy_round3 = accuracy_score(y_true, y_pred_round3)\nprint(f\"Accuracy Round 3: {accuracy_round3}\")\n\n# 可视化一些样本图像和最终的预测结果\nfor i in range(num_samples):\n    plt.imshow(test_dataset[i][0].permute(1, 2, 0).numpy().squeeze(), cmap='gray')\n    true_label = fashion_labels[y_true[i]]\n    predicted_label = fashion_labels[y_pred_round3[i]] if y_pred_round3[i] != -1 else \"Unknown\"\n    plt.title(f'True: {true_label}, Pred: {predicted_label}')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-30T13:14:01.604130Z","iopub.status.idle":"2024-09-30T13:14:01.604742Z","shell.execute_reply.started":"2024-09-30T13:14:01.604423Z","shell.execute_reply":"2024-09-30T13:14:01.604454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 综合","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torchvision import datasets, transforms\nimport openai\nimport base64\nimport requests\n\nimport io\nfrom PIL import Image\nfrom sklearn.metrics import accuracy_score\nimport matplotlib.pyplot as plt\n\n# 设置API密钥\nopenai.api_key = ' '\n\n# 预定义Fashion MNIST标签\nfashion_labels = [\n    'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'\n]\n\n# 定义图像转换，将图像转换为Tensor并标准化\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5,), (0.5,))\n])\n\n# 加载Fashion MNIST测试数据\ntest_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n\n# 创建数据加载器\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n\n# 限制处理图像的数量\nnum_samples = 50\n\n# 函数：将图像编码为base64\ndef encode_image(image):\n    if image.mode == 'RGBA':\n        image = image.convert('RGB')\n\n    buffered = io.BytesIO()\n    image.save(buffered, format=\"JPEG\")\n    return base64.b64encode(buffered.getvalue()).decode('utf-8')\n\n# 第一步：输入自定义图片作为概念理解的预置\ndef get_image_prompt():\n    image_path = input(\"Enter the path of the image to use as a conceptual prompt: \")\n    try:\n        image = Image.open(image_path)\n        return encode_image(image)\n    except Exception as e:\n        print(f\"Could not open image: {e}\")\n        return None\n\n# 第二步：输入自定义文本作为附加概念学习\ndef get_additional_concept_text():\n    return input(\"Enter a text prompt to further teach the model some concepts: \")\n\n# 第三步：输入用于分类的文本prompt\ndef get_text_prompt():\n    return input(\"Please enter your text prompt: \")\n\n# 获取用户输入的重新分类提示\ndef get_reclassification_prompt():\n    return input(\"Enter the reclassification prompt for incorrect answers: \")\n\n# 函数：使用API进行图像分类\ndef classify_image(image_tensor, prompt_text):\n    pil_image = transforms.ToPILImage()(image_tensor[0])\n    base64_image = encode_image(pil_image)\n\n    headers = {\n        \"Content-Type\": \"application/json\",\n        \"Authorization\": f\"Bearer {openai.api_key}\"\n    }\n\n    messages_content = [\n        {\n            \"type\": \"text\",\n            \"text\": prompt_text\n        },\n        {\n            \"type\": \"image_url\",\n            \"image_url\": {\n                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n            }\n        }\n    ]\n\n    payload = {\n        \"model\": \"gpt-4o-2024-08-06\",\n        \"messages\": [\n            {\n                \"role\": \"user\",\n                \"content\": messages_content\n            }\n        ],\n        \"max_tokens\": 300\n    }\n\n    try:\n        response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n        \n        if response.status_code == 200:\n            model_response = response.json()\n            model_content = model_response['choices'][0]['message']['content'].strip()\n            print(f\"Model response: {model_content}\")\n\n            for i, label in enumerate(fashion_labels):\n                if label.lower() in model_content.lower():\n                    return i\n        else:\n            print(f\"Request failed with status: {response.status_code}, {response.text}\")\n\n    except Exception as e:\n        print(f\"Error processing image: {e}\")\n\n    return -1\n\n# 再次分类不正确答案的函数\ndef reclassify_incorrect(y_pred, y_true, images, incorrect_prompt):\n    y_pred_rechecked = y_pred.copy()\n    for idx, predicted in enumerate(y_pred):\n        if predicted != y_true[idx]:\n            print(f\"Re-evaluating index {idx}: Original prediction was incorrect.\")\n            y_pred_rechecked[idx] = classify_image(images[idx], incorrect_prompt)\n    return y_pred_rechecked\n\n# 存储预测结果和真实标签\ny_pred = []\ny_true = []\nimages = []  # 存储图像以便于重新分类\n\n# 获取图像prompt\nbase64_image_prompt = get_image_prompt()\nif not base64_image_prompt:\n    print(\"Image prompt not obtained, exiting program.\")\n    exit()\n\n# 将图像prompt用于概念理解，并展示大模型的回复\nheaders = {\n    \"Content-Type\": \"application/json\",\n    \"Authorization\": f\"Bearer {openai.api_key}\"\n}\n\nconcept_payload = {\n    \"model\": \"gpt-4o-2024-08-06\",\n    \"messages\": [\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\n                    \"type\": \"image_url\",\n                    \"image_url\": {\n                        \"url\": f\"data:image/jpeg;base64,{base64_image_prompt}\"\n                    }\n                },\n                {\n                    \"type\": \"text\",\n                    \"text\": \"Please use this image to understand the concept for further classification tasks.\"\n                }\n            ]\n        }\n    ],\n    \"max_tokens\": 300\n}\n\ntry:\n    concept_response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=concept_payload)\n    if concept_response.status_code == 200:\n        concept_model_response = concept_response.json()\n        concept_model_content = concept_model_response['choices'][0]['message']['content'].strip()\n        print(f\"Conceptual understanding response: {concept_model_content}\")\n    else:\n        print(f\"Concept setup failed with status: {concept_response.status_code}, {concept_response.text}\")\nexcept Exception as e:\n    print(f\"Error setting concept: {e}\")\n\n# 输入附加文本概念，并展现大模型的回复\nadditional_concept_text = get_additional_concept_text()\nadditional_concept_payload = {\n    \"model\": \"gpt-4o-2024-08-06\",\n    \"messages\": [\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\n                    \"type\": \"text\",\n                    \"text\": additional_concept_text\n                }\n            ]\n        }\n    ],\n    \"max_tokens\": 300\n}\n\ntry:\n    additional_concept_response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=additional_concept_payload)\n    if additional_concept_response.status_code == 200:\n        additional_concept_model_response = additional_concept_response.json()\n        additional_concept_model_content = additional_concept_model_response['choices'][0]['message']['content'].strip()\n        print(f\"Additional concept understanding response: {additional_concept_model_content}\")\n    else:\n        print(f\"Additional concept setup failed with status: {additional_concept_response.status_code}, {additional_concept_response.text}\")\nexcept Exception as e:\n    print(f\"Error setting additional concept: {e}\")\n\n# 获取用户定义的文本提示词\nprompt_text = get_text_prompt()\n\n# 获取用户输入的重新分类提示\nreclassification_prompt = get_reclassification_prompt()\n\n# 遍历测试加载器中的样本\nfor idx, (image, label) in enumerate(test_loader):\n    if idx >= num_samples:\n        break\n    images.append(image)\n    predicted_label = classify_image(image, prompt_text)\n    y_pred.append(predicted_label)\n    y_true.append(label.item())\n\n# 计算第一轮准确率\naccuracy_round1 = accuracy_score(y_true, y_pred)\nprint(f\"Accuracy Round 1: {accuracy_round1}\")\n\n# 第二轮：使用用户输入的提示对不正确的答案进行重新分类\ny_pred_round2 = reclassify_incorrect(y_pred, y_true, images, reclassification_prompt)\naccuracy_round2 = accuracy_score(y_true, y_pred_round2)\nprint(f\"Accuracy Round 2: {accuracy_round2}\")\n\n# 第三轮：再次使用相同的用户输入提示进行再次重新分类\ny_pred_round3 = reclassify_incorrect(y_pred_round2, y_true, images, reclassification_prompt)\naccuracy_round3 = accuracy_score(y_true, y_pred_round3)\nprint(f\"Accuracy Round 3: {accuracy_round3}\")\n\n# 可视化一些样本图像和最终的预测结果\nfor i in range(num_samples):\n    plt.imshow(test_dataset[i][0].permute(1, 2, 0).numpy().squeeze(), cmap='gray')\n    true_label = fashion_labels[y_true[i]]\n    predicted_label = fashion_labels[y_pred_round3[i]] if y_pred_round3[i] != -1 else \"Unknown\"\n    plt.title(f'True: {true_label}, Pred: {predicted_label}')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-09-30T13:14:01.606355Z","iopub.status.idle":"2024-09-30T13:14:01.607011Z","shell.execute_reply.started":"2024-09-30T13:14:01.606674Z","shell.execute_reply":"2024-09-30T13:14:01.606705Z"},"trusted":true},"execution_count":null,"outputs":[]}]}